\documentclass{beamer} 
\usepackage[orientation=landscape,size=a1]{beamerposter}

\usetheme{uclposter}


\useinnertheme{blockborder}
\setbeamercolor{block body}{bg=white,fg=black}


\title{Home Depot Kaggle Competition: building a search engine for products}
\author{Michal Daniluk, Dorota Kapturkiewicz and Thomas Nedelec}
\institute{%
  Department of Computing Science,
  University College London
}

% \beamertemplategridbackground[1cm]

\setbeamersize{text margin left=2cm,text margin right=2cm}

\newlength\blockcolsep
\setlength\blockcolsep{2ex}
\newlength\postercolumnsep
\setlength\postercolumnsep{2cm}

\newlength\postercolumnwidth
\setlength\postercolumnwidth{0.3333\textwidth-0.66666\postercolumnsep}

\newlength\totalwidth
\setlength\totalwidth{\textwidth+3ex}

\begin{document}
\begin{frame}[t]{}
\centering
\begin{columns}[totalwidth=\totalwidth]
  \begin{column}[t]{\postercolumnwidth}
    \centering
    \begin{block}{Problem}
\small
 The goal of this competition is not to improve the Search Engine of Home Depot. 
\\ The aim is to design a tool that lets to \textbf{evaluate the quality of a search engine algorithm}. \\Home Depot is using the search relevancy to qualify the quality of a new algorithm. For some queries on the Home Depot website, the IR systems is outputing some particular Home DepoT product and \textbf{several human raters} to give a grade betwen 1 and 3 to judge the revelancy of the product according to the query. 
\\The aim of the competition is to try to \textbf{automatize this judging process}. It will hep to increase the number of search engine algorithms that Home Depot is able to test.
    \end{block}
    %
    \begin{block}{IR algorithm: Lucene}
We decided to use Apache Lucene because members of the team were used to it. It is a little bit more complicated version of tf-idf. It is used for instance by ElasticSearch.
\\ We run a script to build an index which lets to know the difference frequence of words in each file. It is then easy to know which products fits the best the query.



    \end{block}
    %
\begin{block}{Results}
\small
      The competition leaderbord is based on a score computed on the Root mean Squared error compare to the score given human raters:
\begin{equation}
RMSE=\frac{1}{size(TestSet)} \sum_{(q_{i},p_{i})} (scorePredicted(q_{i},p_{i})-TrueHumanScore(q_{i},p_{i}))^{2}
\end{equation}
We are currently 885 over 1380 reaching a RMSE of 0.4913. The gap with 400th rank is only of 0.01.
    \end{block}
\end{column} 
    
  %
  \begin{column}[t]{\postercolumnwidth}
    \centering
\begin{block}{Datasets available}
\small
The task is thus to try to mimick the process made by a human rater to judge the quality of an output according to a particular query. For the task, we are provided several datasets: 
\begin{itemize}
\item the instructions given to a human rater 
\item some \textbf{descriptions of the different products} and some additional informations
\item\textbf{a training set} where we have access to the average grade given by a judge to a pair query-product returned by the algorithm
\item a test set where we need to \textbf{predict the relevance score for a particular pair query-product}
\end{itemize}
\textbf{Size of data sets}:
\begin{itemize}
\item product descriptions: we have 125000 product's description. 
\item training set: we have 74068 trio query-product-relevance score
\item test set: we need to predict the score of 16600 pairs of query-product
\end{itemize}     


    \end{block}
% 
 \begin{block}{Feature Engineering}
We combined features based on Lucene together with traditional NLP features like words n-grams. Examples of our features are as follows:

\begin{itemize}

\item place of an answer in Lucene ranking crated for given query
\item Lucene score of an answer for given query
\item fraction of 1-grams/ 2-grams from query in answer's description/title/brand/attributes
\item average frequency of 1-grams/ 2-grams in answer's description/title 


\end{itemize}

    \end{block}
    % 
  \begin{block}{Ways of improvement}
    Some content
    \end{block}
  \end{column}
  %
  \begin{column}[t]{\postercolumnwidth}
    \centering
     \begin{block}{Preprocessing}
 \small
The idea of our agorithm was to build our own search engine and then try to see the results of the query. we then check the rank of the product we want to match in the query result to build a feature. We try to build different scores and then try to unify them through the training of a regressor on the training set provided by Home Depot. 
\\Preprocessing steps to build our IR algorithm (use of several python libraries): 
\begin{itemize}
\item nltk word tokenization: just tokenize the data
\item stopwords removal: delete all the useless words in the description of the product
\item porter stemming: our IR algorithm will be based of frequences of words: thus stemming lets to avoid having lot of different words of the same family with small frequences
\item create a text fil for each product
\end{itemize}
   
    \end{block}


    \begin{block}{Machine Learning algorithm}
\small
To try to train build our predicter on the different features we build we tried to train several algorithms. In all cases, we used the algorithms pre-implemented in scikitlearn.  
\begin{itemize}
\item Single Vector Machine regressor
\item Random Forest 
\item Adaboost regressor
In all cases, we implemented grid search to try to find best parameters


\end{itemize}


    \end{block} 

    \begin{block}{Conclusion}
      Some Content
    \end{block}
  \end{column}
 \end{columns}

\end{frame}



\end{document}
